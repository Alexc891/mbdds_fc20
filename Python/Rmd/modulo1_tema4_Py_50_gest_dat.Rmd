
## GESTIÓN DE DATOS

__[Abre en Colab](https://colab.research.google.com/github/griu/mbdds_fc20/blob/master/Python/modulo1_tema4_Py_50_gest_dat.ipynb)__ *: <span style="color:rgba(255, 99, 71, 0.8)">Padawan! Cuando inicies sesión en Colab, prepara el entorno ejecutando el siguiente código.</span>*

A continuación, se presentan las funciones para la lectura/escritura de datos, cruce y construcción de tablas resumen. 

Al final del capítulo se presenta la forma de manejar datos temporales.

##### ACTIVIDAD GUIADA 2.5

Se trata de analizar los personajes de la serie:

>     «Preferiría ser un monstruo que cree en algo, que sacrificaría todo para mejorar la galaxia, que ser alguien que se quede al margen y mire como si no tuviera repercusión en ellos.» 
    ―Princesa Leia Organa 


Esta actividad consiste en cruzar datos de personajes y planetas para construir descriptivos resumen de los datos de personajes.

El primer paso consiste en cargar los datos de los personajes y planetas.

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()  # para el estilo de graficos

entidades = ['planets','starships','vehicles','people','species']
entidades_df = {x: pd.read_pickle('www/' + x + '_df.pkl') for x in entidades}

# planetas
planets_df = entidades_df['planets'][["climate","temperate_tropical","population","url"]].dropna()

# Datos principales
people_df = entidades_df['people'][["height","mass","eye_color","birth_year","gender","homeworld"]].dropna()

people_df.head()
```

```{python}
planets_df.head()
```

### IMPORTAR Y EXPORTAR DATOS

La forma más simple de importar datos estructurados (en forma de matriz de filas y columnas), es a través de los DataFrames. El motivo es simple, estos objetos permiten almacenar datos de distinto tipo en un único objeto o tabla de datos.

#### LECTURA TEXTO CON SEPARADOR

Para leer el siguiente fichero de texto:

```{python}
# mostramos las 5 primeras filas
n=5
with open('www/mtcars.csv') as f:
    muestra_texto = ""
    for i in range(5):
        muestra_texto +=f.readline()
print(muestra_texto)
```

Dado que se trata de un fichero con un carácter separado, la función genérica para este tipo de ficheros es `pd.read_table()`.

```{python}
mtcars = pd.read_table("www/mtcars.csv",sep=',', decimal=".")
mtcars.head()
```

Se puede personalizar la carga con los siguiente parámetros:

- `decimal`: El separador decimal.
- `sep`: El separador de columnas

También es común el uso de `enconding="latin_1"` cuando el fichero se ha creado con Windows.

Dada la estructura del fichero, con `pd.read_csv()` la carga es más simple.

```{python}
mtcars = pd.read_csv("www/mtcars.csv")
```

A parte de `.head()`, es una buena práctica verificar su carga con `.shape()`, y `describe()`.

```{python}
mtcars.shape
```

```{python}
mtcars.describe()
```

#### ESCRITURA TEXTO CON SEPARADOR

Para la escritura, puedes utilizar sus equivalentes: `.to_csv()`. Cabe destacar algunas pequeñas variaciones.  

```{python}
mtcars.to_csv("www/mtcars2.csv", decimal=",", sep=";", index=False, encoding="latin_1")
```

- `index`: Campo lógico True, False. Por defecto, inserta el número de fila.

Observa como el nuevo csv ahora tiene el formato de csv europeo con codificación windows.

```{python}
# mostramos las 5 primeras filas
n=5
with open('www/mtcars2.csv') as f:
    muestra_texto = ""
    for i in range(5):
        muestra_texto +=f.readline()
print(muestra_texto)
```

Para leer texto con ancho fijo revisa la función [pd.read_fwf()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_fwf.html).

#### LECTURA Y ESCRITURA EN FORMATO PICKLE

Los objetos Python se pueden hacer persistentes en disco con el formato pickle.

> **Sabías que**: pickle significa pepinillo o vinagreta. Es decir, que el formato pickle significa que estamos poniendo los objetos Python en conserva.  

Para guardar un DataFrame en formato pickle utiliza el método `.to_pickle("nombre.pkl")`.

```{python}
mtcars.to_pickle("www/mtcars.pkl")
```

```
!dir www/mtcars*

## www/mtcars2.csv  www/mtcars.csv  www/mtcars.pkl
```


Para cargar un fichero pickle (sacarlo de la conserva), se utiliza `pd.read_pickle()`.

```{python}
mtcars_pkl = pd.read_pickle("www/mtcars.pkl")
mtcars_pkl.shape
```

### CRUCE ENTRE TABLAS

Para definir un cruce en pandas, es muy importante ser conscientes de la presencia de los índices fila y columna de las tablas origen. En este sentido se puede realizar el cruce por 3 sistemas distintos:

- Por índices
- Por ordenación
- Por campos clave

Veamos los dos últimos, ya que el cruce por índices es la opción por defecto en todas las funciones que se van a mostrar.

#### CRUCES POR ORDENACIÓN SIN ÍNDICE COMPARTIDO

Una forma de cruzar 2 DataFrames es a partir de la ordenación compartida, ya sea de las filas o las columnas.

##### ORDENACIÓN DE TABLAS

Para ordenar una serie, se utiliza el método `.sort.values()`.

```{python}
a = people_df.birth_year.sort_values(ascending=False)
a.head()
```

- `ascending`: Campo lógico. Por defecto ordena de forma ascendente.

En DataFrames, no es muy distinto, pero ahora hay que indicar el campo de ordenación en el parámetro ` by`.

```{python}
people_df_Ord = people_df.sort_values(by=["gender","height"], ascending=[True, False])
people_df_Ord.head()
```

Observa como `ascending` permite escoger una ordenación distinta para cada campo de ordenación. 

De esta forma sabemos que *Padmé Amidala*, con 185 cm, era la mujer más alta de la serie.

##### UNIÓN POR COLUMNAS SIN ÍNDICE COMPARTIDO

Para unir las columnas de dos DataFrames que comparten ordenación utiliza `pd.concat()`.

Para ver un ejemplo, antes vamos a preparar 2 tablas de ejemplo. Para la primera, seleccionamos las 4 primeras columnas y reseteamos el índice con `.reset_index()`.

```{python}
people_df1 = people_df.iloc[:,:4].reset_index()
people_df1.head()
```

> **Importante**: Al resetar el índice con `.reset_index()`, éste se ha convertido en un nuevo campo **name** de la tabla.

Ahora la segunda tabla con el resto de campos.

```{python}
people_df2 = people_df.iloc[:,4:]
people_df2.head()
```

Las dos tablas `people_df1` y `people_df2`, comparten ordenación, pero no un mismo índice. Para realizar el cruce `ignore_index=True`  evita que la función utilice los índices.

```{python}
a = pd.concat([people_df1, people_df2], ignore_index=True)
a.head()
```

###### UNIÓN POR FILAS

Para unir dos DataFrames con la misma ordenación de sus columnas, se puede utilizar pd.concat, aunque es más directo con el método `.append()`.

```{python}
a1 = people_df.iloc[0:2,:2]
a2 = people_df.iloc[3:5,:2]
a = a1.append(a2)
a1
```

```{python}
a2
```

```{python}
a
```

> **Importante**: en caso de no compartir los mismos nombres de columnas, se puede utilizar igualmente el parámetro `ignore_index=True`.

#### CRUCE POR CAMPOS CLAVE

Antes de realizar un cruce por campos clave es importante saber si éste tiene valores duplicados. 

##### VECTOR DE CLAVES

Para obtener las claves únicas de una serie o DataFrame utiliza `.unique()`.

```{python}
a = people_df.homeworld.unique()
a
```

Para saber qué filas de un DataFrame están duplicadas, utiliza `.duplicated()`.

```{python}
people_df_dup = people_df.iloc[[1,1,2,3,3,4,5,5,6],:]
people_df_dup.duplicated()
```

> **Observa**: la función `.duplicated()` marca como `False` la primera copia y como `True` la segunda copia.

Para eliminar los duplicados, se utiliza `.drop_duplicates()`. Con `keep=False` se elimina todas filas con duplicados.

```{python}
people_df_dup.drop_duplicates(keep=False)
```

##### FUSIÓN CON CLAVES

Para cruzar 2 tablas con claves, utiliza `pd.merge()`.

###### INNER JOIN

Recordemos que inner join consiste en construir una tabla que tenga claves coincidentes en las tablas.

Para ver un ejemplo, vamos a seleccionar, por un lado planetas con un clima malo, es decir, que no sea temperado o tropical.

```{python}
planets_clima_df = planets_df[planets_df.temperate_tropical==0]
planets_clima_df
```

Por otro lado, seleccionamos personajes con color de ojos azul.

```{python}
people_eyes_df = people_df[people_df.eye_color=="blue"]
people_eyes_df
```

El campo coincidente clave para el cruce es `url` que equivale al campo `homeworld` de people_df.

```{python}
a_inner = pd.merge(people_eyes_df, planets_clima_df, left_on=["homeworld"], right_on=["url"])
a_inner.head()
```

Vemos que hay cuatro personajes de ojos azules que nacieron en planetas con mal clima. El problema es que con el cruce se han perdido los nombres de ambas tablas contenidos en los índices. Rescatemos antes del cruce con la función reset_index().

```{python}
people_eyes_df = people_eyes_df.reset_index()
planets_clima_df = planets_clima_df.reset_index()

a_inner = pd.merge(people_eyes_df, planets_clima_df, left_on=["homeworld"], right_on=["url"])
a_inner.head()
```

> **Observa**: el campo `name` estaba duplicado en ambas tablas sin ser campo clave. `pd.merge()` ha incluido ambos en la tabla final añadiendo el sufijo `_x` para tabla la izquierda (people_df) y `_y` tabla derecha (planets_df).

El cruce se ha hecho de forma implícita con la opción `how="inner"`. 

###### OUTER JOIN

Para conservar **todos los registros de las tablas originales**, tanto de la tabla izquierda como derecha, coincida o no, se utiliza el parámetro `how = "outer"`.

```{python}
a_outer = pd.merge(people_eyes_df, planets_clima_df, how = "outer", left_on=["homeworld"], right_on=["url"])
a_outer
```

Observa ahora, no ha descartado ningún registro de las tablas origen. Además, ha rellenado con `NaN` los campos que no cruzan. Este comportamiento en SQL es conocido como *FULL JOIN* o *OUTTER JOIN* .

###### LEFT JOIN

Para imponer que conserve **todos los valores origen de la tabla izquierda** y que descarte los de la taba derecha que no sean compartidos utiliza `how="left"`.

```{python}
a_left = pd.merge(people_eyes_df, planets_clima_df, how="left", left_on=["homeworld"], right_on=["url"])
a_left
```

Ahora ha conservado todos los personajes.

###### RIGHT JOIN

Para preservar **todos los valores de la tabla derecha** utiliza `how="right"`.

```{python}
a_right = pd.merge(people_eyes_df, planets_clima_df, how="right", left_on=["homeworld"], right_on=["url"])
a_right
```

Ahora ha conservado todos los planetas con mal clima.

###### DEFINCIÓN DE LAS CLAVES

Cuando las claves son campos comunes no es necesario definir los campos `left_on` y `right_on`. 

Por otro lado, si uno de los campos clave está contenido en el índice del DataFrame, se puede utilizar el parámetro `left_index=True` o `right_index=True` o ambos.  

### RESUMENES DE AGREGADOS 

Las librerías numpy y pandas implementan una extensa colección de funciones de resumen.

#### DESCRIBE

Para tener una primera impresión sobre las estadísticas de un DataFrame se utiliza `.describe()`.

Antes incluyamos a people_df algunas variables nuevas de distinto tipo y además algunos missings.

```{python}
people_dfSumm = people_df.copy()

people_dfSumm.loc[people_dfSumm.index[[0,2,4,8,20]],'height'] = np.nan
people_dfSumm.loc[people_dfSumm.index[[0,2,4,8,20]],'eye_color'] = np.nan
people_dfSumm["Alto"] = people_dfSumm.height>188
people_dfSumm["Fecha_hoy"] = np.datetime64('2020-09-06')

people_dfSumm.head()
```

```{python}
people_df.describe()
```

Por defecto, calcula los siguientes estadísticos básicos sobre variables numéricas:

- `count`: Número de valores informados (distintos de NaN).
- `mean`: Media.
- `str`: Desviación típica.
- `min`: Mínimo.
- `25%`: Cuantil 25%.
- `50%`: Cuantil 50% o mediana.
- `75%`: Cuantil 75%.
- `max`: Máximo.

Para incluirlas todas se utiliza `include='all'`.

```{python}
people_dfSumm.describe(include='all')
```

Ahora, para las variables no numéricas, informa del `count` y además:

- `unique`: Número de valores únicos.
- `top`: Valor más frecuente.
- `freq`: Frecuencia observada del valor top.
- `first` y `last`: Para las datetime se informa de la primera y última fecha.

#### ESTADÍSTICOS BASICOS

Para calcular los estadísticos mostrados en la función `.describe()` con funciones numpy:

```{python}
def resumen_numericas_numpy(x):
    return {
        "count":np.sum(~np.isnan(x))
        ,"mean":np.nanmean(x)
        ,"std":np.nanstd(x)
        ,"min":np.min(x)
        ,"quantile 25, 50, 75":np.nanquantile(x, [0.25,.5,.75])
        ,"max":np.max(x)}
    
resumen_numericas_numpy(people_dfSumm.height)
```

> **Importante**: Las funciones equivalentes np.mean, np.std o np.quantile devuelven NaN cuando el array contienen algún valor NaN.

Ahora con funciones equivalentes en pandas:

```{python}
def resumen_numericas_pandas(x):
    return {
        "count":x.count()
        ,"mean":x.mean()
        ,"std":x.std()
        ,"min":x.min()
        ,"quantile 25, 50, 75":x.quantile([0.25,.5,.75])
        ,"max":x.max()}
    
resumen_numericas_pandas(people_dfSumm.height)
```

Observa que la opción por defecto en pandas, es eliminar los NaN.

```{python}
def resumen_no_numericas_numpy(x):
    value, counts = np.unique(x[~pd.isnull(x)], return_counts=True)
    return {
        "count":np.sum(~pd.isnull(x))
        ,"unique": len(np.unique(x[~pd.isnull(x)]))
        ,"top": value[np.argmax(counts)]
        ,"freq":np.max(counts)}

resumen_no_numericas_numpy(people_dfSumm.eye_color)
```

> **Importante**: En variables no numéricas se ha filtrado los valores None o NaN con pd.isnull().

Ahora con funciones pandas.

```{python}
def resumen_no_numericas_pandas(x):
    value, counts = np.unique(x[~pd.isnull(x)], return_counts=True)
    return {
        "count":x.count()
        ,"unique": x.nunique()
        ,"top": list(x.mode())[0]
        ,"freq":(x==list(x.mode())[0]).sum()}

resumen_no_numericas_pandas(people_dfSumm.eye_color)
```

#### TABLAS DE FRECUENCIAS

##### FRECUENCIAS DE UNA VARIABLE

Para obtener las frecuencias de una serie pandas se utiliza `.value_counts()`.

```{python}
people_dfSumm.eye_color.value_counts()
```

Por defecto, ordena de más a menos frecuente. 

Se puede ordenarlo posteriormente por el índice con `.sort_index()`.

```{python}
people_dfSumm.eye_color.value_counts().sort_index()
```

##### TABLAS CRUZADAS

Para obtener las frecuencias de dos variables utiliza `pd.crosstab()`.

```{python}
pd.crosstab(people_dfSumm.eye_color,people_dfSumm.gender)
```

##### TRAMEAR VARIABLES

En pandas series se puede tramear una variable con la función `pd.cut()`

```{python}
people_dfSumm["Altura_Cat"] = pd.cut(people_dfSumm.height,[-np.infty,171,189,np.infty], right=False)

people_dfSumm[["height","Altura_Cat"]].head(8)
```

Observa como pd.cut() ha trameado en intervalos la variable `height`. Con `right=False` se le pide que el intervalo sea cerrado a la izquierda y abierto a la derecha.

Las frecuencias de cada categoría.

```{python}
people_dfSumm["Altura_Cat"].value_counts().sort_index()
```

> **Importante**: `pd.cut()` crea una variable de tipo `pd.Categorical`. Este tipo de datos contienen .categories() y .codes(), parecidos a los `factores` vistos en R.

```{python}
people_dfSumm["Altura_Cat"].dtype
```

Para recuperar las categorías, utiliza `.cat.categories`

```{python}
people_dfSumm["Altura_Cat"].cat.categories
```

Los códigos internos de los valores `.cat.codes`.

```{python}
people_dfSumm["Altura_Cat"].cat.codes.head()
```

Para modificar las etiquetas puedes modificar directamente los índices de las categorías.

```{python}
people_dfSumm["Altura_Cat"].cat.categories = ["Bajo/a","Mediano/a","Alto/a"]

people_dfSumm[["height","Altura_Cat"]].head(8)
```

##### ACTIVIDAD GUIADA 2.5

Veamos ahora, un resumen de la altura de los personajes por el tipo de clima de su planeta.

Los pasos a realizar son:

1. Cruzamos las tablas de personajes y planetas
1. Construimos la variable trameada de altura en puntos de corte 171 cm  y 189 cm. 
1. Cruzamos la altura con el clima del planeta.

```{python}
personajes_df = pd.merge(people_df.reset_index(), 
                         planets_df.reset_index(), left_on=["homeworld"], right_on=["url"])
personajes_df.index= personajes_df.name_x         # indexamos por nombre del personaje
personajes_df.head()
```

```{python}
personajes_df["Altura_Cat"] = pd.cut(personajes_df.height,[-np.infty,171,189,np.infty], right=False)
personajes_df.Altura_Cat.cat.categories = ["Bajo/a","Mediano/a","Alto/a"]

personajes_df.Altura_Cat.value_counts().sort_index()
```

```{python}
summ_altura_clima = pd.crosstab(personajes_df.Altura_Cat,personajes_df.temperate_tropical)

summ_altura_clima
```

Para saber el % de personajes de cada estatura que vive en clima temparado-tropical o no, utiliza `normalize="index"`. De esta forma cada fila va a sumar 1 (es decir, 100%).

```{python}
summ_altura_clima = pd.crosstab(personajes_df.Altura_Cat,personajes_df.temperate_tropical, normalize="index")

summ_altura_clima.sort_index(axis=1, ascending=False)
```

Gráficamente.

```{python}
summ_altura_clima = summ_altura_clima.sort_index(axis=1, ascending=False) # cambiamos orden columnas para el gráfico
summ_altura_clima
```

```{python}
g = summ_altura_clima.plot.bar(stacked=True,include_bool=True, alpha=0.75, rot=0)
g.legend(bbox_to_anchor=(1, 0.8),title="Temperado o tropical")
plt.gcf().subplots_adjust(bottom=0.15,right=0.7)
plt.title("% personajes en cada clima por Altura")
plt.ylabel("%")
plt.xlabel("Altura");
plt.show();
```

Se observa que un **70% de los personajes bajos** han nacido en climas temperado o tropicales, frente al **60% de los personajes altos**.

### AGREGADOS POR SUBGRUPOS

Además de frecuencias, es necesario calcular más estadísticos relevantes. Por ejemplo, la mediana de la edad (birth_year), el peso (mass) mínimo de los personajes, o la media de habitantes (population) de sus planetas por tipo de clima y tramo de altura (alto, medio bajo) de los personajes.

#### AGRUPACIÓN O GROUPBY

Para poder dar una respuesta al problema planteado, antes es necesario introducir el concepto de Agrupación o GroupBy.

La solución planteada en pandas es la de definir una partición de la tabla mediante `.grouby()`. Una vez definida la petición se puede calcular estadísticos de resumen.

```{python}
summ1_altura_clima = personajes_df.groupby(["temperate_tropical"
                                            ,"Altura_Cat"])[["mass","birth_year","population"]].median()

summ1_altura_clima
```

Observa cómo se ha aplicado la función mean sobre cada una de las variables para cada combinación de clima de los planetas y altura de los personas.

También aparece un elmento nuevo, es la capacidad de los DataFrames de tener un índice compuesto por más de una variable, en este caso `temperate_tropical` y `Altura_Cat`.

Una forma de sortear los índices múltiples, es incorporarlos como variables con `.reset_index()`.

```{python}
summ1_altura_clima = summ1_altura_clima.reset_index()

summ1_altura_clima
```

Ahora los 2 índices se han convertido a columnas de la tabla.

#### AGGREGATE

Para aplicar distintas funciones de agregación a distintas variables, se utiliza `.aggregate()` o abreviadamente `.agg()` de forma combinada con `.groupby()`. 

Un primer pase, es aplicar varias funciones a todas las variables seleccionadas del data frame.

```{python}
summ2_altura_clima = personajes_df.groupby(
    ["temperate_tropical","Altura_Cat"])[
    ["mass","birth_year","population"]].agg(["min","median","mean"])
summ2_altura_clima
```

Observa que ahora hay múltiples índices columna.

```{python}
summ2_altura_clima.columns
```

Una forma de combinar los dos niveles del índice en un solo nombre del tipo `Variable_Estadistico`, es mediante la función de vectorización de funciones `.map()` (ver más información en: [map](https://www.w3schools.com/python/ref_func_map.asp)). La función para combinar los 2 niveles es:  `"_".join`.

```{python}
summ2_altura_clima.columns = summ2_altura_clima.columns.map("_".join)  # combina nombres columna
summ2_altura_clima = summ2_altura_clima.reset_index() # pasamos los indices fila a columnas.

summ2_altura_clima
```

Para resolver la cuestión planteada, se necesita poder decidir, qué estadsítico se quiere aplicar en cada variable.

Se puede definir qué estadístico se va a aplicar sobre cada variable, mediante un diccionario.

```{python}
summ3_altura_clima = personajes_df.groupby(
    ["temperate_tropical","Altura_Cat"]).agg({'name_x': 'count', 'birth_year': 'median'
                                              ,'mass':'min','population':'mean'})

summ3_altura_clima = summ3_altura_clima.reset_index()
summ3_altura_clima
```

Observa, por ejemplo, que hay 2 personajes de estatura baja que nacieron en un planeta de clima NO temperado o tropical, con mediana de edad 79.5 años BBY, peso mínimo 75 Kg y que viven en planetas con una media de 200.000 habitantes.

Para poder identificar cada fila con una etiqueta, vamos a combinar las variables de temperado_tropical con la altura del personaje.  

```{python}
summ3_altura_clima["clima_altura"] = pd.Series(
    np.where(summ3_altura_clima["temperate_tropical"]==0,"Clima Malo","Clima Bueno")
    ) + "-" + summ3_altura_clima["Altura_Cat"].astype(str)

summ3_altura_clima
```

Para representar este Pandas de forma gráfica, se puede utilizar directamente `.plot.scatter()`.

```{python}
summ3_altura_clima.plot.scatter(x="birth_year",y="mass",s=20*np.log(summ3_altura_clima.population),c="temperate_tropical");
plt.gcf().subplots_adjust(bottom=0.15, left=0.15)
plt.title("Grupos por clima y altura de los personajes");
plt.xlabel("Edad");
plt.ylabel("Peso");
for index,x in summ3_altura_clima.iterrows():
    plt.text(x["birth_year"],x["mass"]+4,x["clima_altura"],horizontalalignment='center',size=8)
plt.show();
```

Se observa que, los 3 grupos de clima Malo (bolas blancas) tienen personajes de mayor peso. 

#### FILTRADO

A parte de agregar, `.groupby()` se puede utilizar de forma combinada con la función `.filter()` para seleccionar grupos de la tabla original que cumplan ciertas condiciones. 

Por ejemplo, seleccionamos el grupo de persoanjes con un mismo clima y tramo de altura dónde la mediana de edad de este grupo sea superior a 90 años.

```{python}
seleccion1 = personajes_df.groupby(
    ["temperate_tropical","Altura_Cat"]).filter(lambda fila: fila['birth_year'].median() > 90)

seleccion1
```

Vemos como el grupo formado por "Jar Jar Binks", "Chewbacca", "Ki-Adi-Mundi" forman parte del mismo grupo de clima y altura y tienen una edad mediana superior a 90 años.

#### TRANSFORMACIONES

Otra utilidad de `.groupby()` combinado don `.transform()` es poder transformar los datos originales con agregados, de forma simple.

Comparamos la edad de cada personaje, respecto a la mediana de su grupo de clima y tramo de altura.

```{python}
compara1 = personajes_df.groupby(
    ["temperate_tropical","Altura_Cat"]).birth_year.transform(lambda x: np.abs(x - x.median()))

compara1.sort_values(ascending=False).head()
```

Observa como "Jabba Desilijic Tiure" tiene una diferencia de 554 años sobre la media de su grupo. 

#### APLICACIÓN DE FUNCIONES

Finalmente, para ganar aun mayor flexibilidad para transformar datos, `.groupby()` se combina con `.apply()` para poder aplicar transformaciones de forma selectiva en ciertas columnas del DataFrame.   

```{python}
def centrado(x):
    x['Edad_c'] = x['birth_year']-x['birth_year'].median()
    return x

personajes_df2 = personajes_df.groupby(["temperate_tropical","Altura_Cat"]).apply(centrado)

personajes_df2.head()
```

Observa que la nueva variable de Edad_c, permite saber que Luke está 19 años por debajo de la mediana de su grupo de clima (malo) y tramo de altura (mediano).

### TABLAS PIVOTE

Las tablas pivotantes `.pivot_table()` son una solución intermedia entre los `pd.crosstabs()` orientados obtener tablas cruzadas (filas x columnas) y las agregaciones realizadas con `.groupby()`.

Es decir, aplicar distintas funciones de agregación, sobre cruces de filas y columnas predefinidos.

```{python}
personajes_df.pivot_table("birth_year", index='Altura_Cat', columns='temperate_tropical')
```

Esta tabla nos informa de la media de la edad BBY ('birth_year') sobre el cruce de las categorías de altura y clima.

Pivot table, permite crear multiple índice en las filas y columnas.

```{python}
personajes_df.pivot_table("birth_year", index=['gender','Altura_Cat'], columns='temperate_tropical')
```

También seleccionar que función de agregación se requiere en cada cruce definido.

```{python}
personalizarDict = {'name_x': 'count', 'birth_year': 'median'
                                              ,'mass':'min','population':'mean'}
personajes_df.pivot_table(index='Altura_Cat', columns='temperate_tropical'
                          , aggfunc=personalizarDict)
```

Observa cómo se ha obtenido la misma tabla que en el ejercicio con `.agg()`, pero ahora, con otra orientación de filas y columnas.

### DATETIME: GESTIÓN DE FECHAS Y HORARIOS

La librería para gestión de fechas y horarios en Python es `datetime`. Además, también se utiliza la librería de funcionalidades ampliadas `dateutil`. 

```{python}
from datetime import datetime
from dateutil import parser
```

#### CREAR FECHAS  HORAS

Para crear fechas.

```{python}
fecha = datetime(year=2020, month=9, day=7) # con datetime
```

#### OBTENER COMPONENTES

Para obtener los meses y días de la semana en castellano. 

```{python}
import locale

locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')

fecha.strftime('%A')
```

Más información sobre otros componentes en  la [sección strftime](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior), o bien, en la documentación de [datetime](https://docs.python.org/3/library/datetime.html) de Python.

#### DATETIME Y NUMPY

Se pueden definir vectores de tipo de datos datetime64.

```{python}
fecha = np.array('2020-09-07', dtype=np.datetime64)
fecha
```

Ahora se pueden realizar operaciones vectorizadas de forma óptima en numpy.

```{python}
fecha + np.arange(12)
```

También declarar datetime con fecha y hora.

```{python}
np.datetime64('2020-09-07 12:00')
```

#### DATETIME Y PANDAS

Para definir fechas.

```{python}
fecha = pd.to_datetime("2020-9-7")
fecha
```

Convertir.

```{python}
fecha.strftime("%A, %d de %m de %Y")
```

Vectorizar operaciones.

```{python}
fecha + pd.to_timedelta(np.arange(12), 'D')
```

#####  INDEXAR PANDAS CON DATETIME

Combinar ambas funcionalidades aporta mucha utilidad.

```{python}
index = pd.DatetimeIndex(['2019-08-07', '2019-09-07',
                          '2020-08-07', '2020-09-07'])
fecha = pd.Series([0, 1, 2, 3], index=index)
fecha
```

Se puede seleccionar por rangos.

```{python}
fecha['2019-08-07':'2020-08-07']
```

Incluso sólo por año.

```{python}
fecha['2020']
```

#### SERIES TEMPORALES PANDAS

Para definir una serie pandas de datetime.

```{python}
fecha = pd.to_datetime(['2019-08-07', '2019-09-07',
                          '2020-08-07', '2020-09-07'])
fecha
```

Convertir a frecuencia diaria.

```{python}
fecha.to_period('D')
```

Restar fechas.

```{python}
fecha - fecha[0]
```

#### SECUENCIAS DE FECHAS

Para definir una secuencia.

```{python}
pd.date_range('2020-09-03', '2020-09-07')
```

O bien, especificando la longitud de la secuencia y la periodicidad.

```{python}
pd.period_range('2020-07', periods=8, freq='M')
```

#### FRECUENCIAS

Para generar frecuencias utiliza `pd.timedelta_range()`.

```{python}
pd.timedelta_range(0, periods=9, freq="2H30T")
```

Puedes ampliar conocimientos en  la sección de ["Time Series/Date"](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) de la documentación de Pandas.

