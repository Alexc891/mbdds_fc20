
# Ideas clave

- Python es un lenguje de propósito general con un conjunto de paquetes que facilitan la computacion científica en el ámbito de la ciencia de datos.
- Python permite la visualización de datos.
- Python es un lenguaje perfectamente válido para entornos productivos de tratamientos de datos.
- Python interactua de forma simple con distintas bases de datos.
- El entorno Jupyter/Colab aportan capacidades interactivas a Python. Permite tanto desarrollar programas, como análisis de datos.
- Se utiliza en todas las fases de análisis de datos:
   - Adquisición y preparación de los datos (bases de datos, ficheros planos, etc.).
   - Análisis de los datos: construcción de modelos predictivos, de agrupamiento o clasificación, utilidades gráficas para la visualización de datos, etc.
   - Manejo y almacenamiento efectivo de los datos como son los cálculos con matrices. Y un lenguaje de programación bien desarrollado que incluye saltos condicionales, bucles, funciones recursivas, utilidades para la entrada y salida de datos, etc.
   - Comunicación de los resultados: realización de informes para presentación de los resultados y conclusiones. Utiliza Jupyter/Colab combinado con Markdown.
   - Aplicación de los resultados obtenidos: por ejemplo, utilización de modelos predictivos desarrollados para en función de una serie de datos históricos (datos de entrenamiento y test del modelo) predecir ciertas salidas.

# Anexo: Readme de Python

__[Abre en Colab](https://colab.research.google.com/github/griu/mbdds_fc20/blob/master/Python/modulo1_tema4_Py_60_anexo.ipynb)__

#### PREPARACIÓN DEL ENTORNO COLAB

Des de [Colab](http://colab.research.google.com), hay que clonar el repositorio cada vez que inicias un nuevo libro. En los libros se incluye el código necesario para ello.

#### PREPARACIÓN ENTORNO LOCAL-JUPYTER (OPCIONAL)

##### CLONAR REPOSITORIO

En local puedes utilizar el mismo proyecto que has clonado en el [README DE R](../R/README.md). 

Para actualizarlo de nuevo, des de consola.

```
cd mbdds_fc20
git pull
cd Python
```

##### CREAR EN LOCAL UN NUEVO ENVIRONMENT DE ANACONDA

Abrimos una línea de comandos (con *Anaconda 3.0* ya disponible).

- Windows: Escribimos `Anaconda` en el menú Inicio y aparecerá la consola MS-DOS de Anaconda.
- Linux: Abrimos Terminal

```
conda deactivate
conda create -n mbdds_rpy20 python=3.6.9
conda activate mbdds_rpy20
```

Verifica que se ha creado y está activo.

```
conda info --envs
```

##### INSTALA LAS LIBRERIAS DE PYTHON

```
cd mbdds_fc20/Python
conda activate mbdds_rpy20
python -m pip install -r requirementsColab.txt
```

##### PUBLICAR EL KERNEL

Para acceder al nuevo environment desde Jupyter necesitas publicar el kernel.

```
python -m ipykernel install --user --name mbdds_rpy20 --display-name "mbdds_rpy20"
```

Puede tardar unos minutos en publicarse.

##### LANZAR ENTORNO JUPYTER NOTEBOOK

Para acceder al servidor Jupyter. 

```
conda activate mbdds_rpy20
jupyter notebook
```

Debería abrirse un navegador con acceso a Jupyter desde donde podrás acceder a los notebooks. Habitualmente el servidor Jupyter se abre en http://localhost:8888/ .

#### IMPORTAR DATOS DE STARWARS SWAPI

Datos procesados a partir de https://swapi.dev/documentation#root.

```{python}
import requests
import pandas as pd
import numpy as np
```

```
# exec(open('get_entity.py').read())
def get_entity(entity = None, url_base = 'http://swapi.dev/api/'):
# https://swapi.dev/documentation#root
    
    page_num = 1
    results_acum = []
    entity_list = ["films","people","planets","species","starships","vehicles"]
    
    if(entity not in entity_list):
        page_num = None
        print('Call a valid entity: ' + ','.join(entity_list))
    
    while(page_num is not None):
        url = "".join([url_base, entity, '/?page=', str(page_num)])
        rjson = requests.get(url).json()
        results_acum = results_acum + rjson['results']
        if(rjson['next'] is not None):
            page_num = page_num + 1
        else:
            page_num = None
            
    if (len(results_acum) > 0):
        results_df = pd.DataFrame(results_acum)
    else:
        results_df = entity_list
    
    return(results_df)

def str2num(df,num_list):
    num_list = [lab for lab in num_list if lab in df.columns]
    num_list = [lab for lab in num_list if  df[lab].dtype==object]
    for x in num_list:
        if (x=="crew"):
            df.loc[df[x] == "30-165",x] = "165"
        df[x] = pd.to_numeric(df[x].replace('[^0-9\.-]', '', regex=True), errors='coerce')
    return(df)
```

```
res = get_entity()
```

```
res
```

```
films_df = get_entity("films")
people_df = get_entity("people")
planets_df = get_entity("planets")
species_df = get_entity("species")
starships_df = get_entity("starships")
vehicles_df = get_entity("vehicles")

people_df.index = people_df.name
planets_df.index = planets_df.name
species_df.index = species_df.name
starships_df.index = starships_df.name
vehicles_df.index = vehicles_df.name

people_df.drop("name",inplace=True, axis=1)
planets_df.drop("name",inplace=True, axis=1)
species_df.drop("name",inplace=True, axis=1)
starships_df.drop("name",inplace=True, axis=1)
vehicles_df.drop("name",inplace=True, axis=1)
```

```
people_num = ["height","mass","birth_year"]
planets_num = ["diameter","rotation_period","orbital_period","population","surface_water", "gravity"]
species_num = ["average_height","average_lifespan"]
starships_num = ["passengers","length","crew","cost_in_credits","cargo_capacity"
                 ,"hyperdrive_rating","MGLT","max_atmosphering_speed"]
vehicles_num = ["cargo_capacity","cost_in_credits","crew","length","max_atmosphering_speed","passengers"]
```

```
people_df.loc[(people_df["gender"].isin(['n/a', 'none'])) | people_df["gender"].isna(),"gender"] = 'none'
planets_df["temperate_tropical"] = planets_df.climate.apply(lambda x: ("temperate" in x) or ("tropical" in x)).astype(int)
```

```
people_df2 = str2num(people_df,people_num)
planets_df2 = str2num(planets_df,planets_num)
species_df2 = str2num(species_df,species_num)
starships_df2 = str2num(starships_df,starships_num)
vehicles_df2 = str2num(vehicles_df,vehicles_num)
```

```
planets_df2.loc["Bespin","gravity"] = 1.5
```

```
people_df2.to_pickle("www/people_df.pkl")
planets_df2.to_pickle("www/planets_df.pkl")
species_df2.to_pickle("www/species_df.pkl")
starships_df2.to_pickle("www/starships_df.pkl")
vehicles_df2.to_pickle("www/vehicles_df.pkl")
```

```
vehicles_df2.describe()
```

# Bibliografía

- W. McKinney. Python for Data Anlysis. O’Reilly Media, Inc. 2nd ed.; 2017

Profundizar en el uso de Pandas, NumPy y Matplotlib para el análisis y preparación de datos.

- J. VanderPlas. Python Data Science Handbook. O’Reilly Media, Inc.; 2016. Disponible en: http://faculty.marshall.usc.edu/gareth-james/ISL/

Profundizar en el uso de Pandas, Numpy y Machine Learning.

- C. R. Severance. Python para todos. Elliott Hauser, Sue Blumenberg; 2009. Disponible en: https://www.py4e.com/book.php

Cubre todo lo básico de Python más la interacción con bases de datos, visualización y modelado.

# Recursos en internet

- [Cheatsheet de Python](https://www.pythoncheatsheet.org/)
